{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 모델을 활용해 보자\n",
    "\n",
    "앞서 만든 Word2Vec을 Deep Learning 모델로 학습시키면 어떨까요? 이 튜토리얼은 간단한 DNN을 활용하여 Sentiment Analysis를 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prepro import data_prepro, review_to_wordlist, getAvgFeatureVecs\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv( \"../src/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "데이터 전처리 작업을 합니다. 앞선 튜토리얼에서 활용한 Sentence Embedding 기법을 그대로 활용하여 Sentence Embedding Vector를 Deep learning Input으로 활용하려 합니다.\n",
    "\n",
    "학습이 잘 되었는지 확인하기 위해 Train Dataset과 Test Dataset를 구분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_portion = 0.2\n",
    "train_count = int(train.shape[0] * (1 - dev_portion))\n",
    "\n",
    "train_input_data = data_prepro(train['review'][:train_count])\n",
    "train_labels = np.array(train['sentiment'][:train_count], dtype=np.float32)\n",
    "train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "\n",
    "dev_input_data = data_prepro(train['review'][train_count:])\n",
    "dev_labels = np.array(train['sentiment'][train_count:], dtype=np.float32)\n",
    "dev_labels = np.expand_dims(dev_labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_multi_class(labels):\n",
    "    output = np.zeros([labels.shape[0], 2])\n",
    "    for i, (label, o) in enumerate(zip(labels, output)):\n",
    "        if label == 0:\n",
    "            output[i,0] = 1\n",
    "        else:\n",
    "            output[i,1] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = make_multi_class(train_labels)\n",
    "dev_labels = make_multi_class(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 20000\n",
      "Review 1000 of 20000\n",
      "Review 2000 of 20000\n",
      "Review 3000 of 20000\n",
      "Review 4000 of 20000\n",
      "Review 5000 of 20000\n",
      "Review 6000 of 20000\n",
      "Review 7000 of 20000\n",
      "Review 8000 of 20000\n",
      "Review 9000 of 20000\n",
      "Review 10000 of 20000\n",
      "Review 11000 of 20000\n",
      "Review 12000 of 20000\n",
      "Review 13000 of 20000\n",
      "Review 14000 of 20000\n",
      "Review 15000 of 20000\n",
      "Review 16000 of 20000\n",
      "Review 17000 of 20000\n",
      "Review 18000 of 20000\n",
      "Review 19000 of 20000\n",
      "Review 0 of 5000\n",
      "Review 1000 of 5000\n",
      "Review 2000 of 5000\n",
      "Review 3000 of 5000\n",
      "Review 4000 of 5000\n"
     ]
    }
   ],
   "source": [
    "num_features = 300\n",
    "trainDataVecs = getAvgFeatureVecs(train_input_data, model, num_features)\n",
    "devDataVecs = getAvgFeatureVecs(dev_input_data, model, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN 생성\n",
    "\n",
    "tensorflow 모델을 활용하여 간단한 2-layer DNN을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model hyperparameter\n",
    "learning_rate = 0.01\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "total_batch = int(trainDataVecs.shape[0]/batch_size)\n",
    "\n",
    "input_dim = 300\n",
    "hidden_1_dim = 100\n",
    "hidden_2_dim = 100\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([input_dim, hidden_1_dim], stddev=0.01))\n",
    "b1 = tf.Variable(tf.constant(0.0))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([hidden_1_dim, hidden_2_dim], stddev=0.01))\n",
    "b2 = tf.Variable(tf.constant(0.0))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_2_dim, num_classes], stddev=0.01))\n",
    "b3 = tf.Variable(tf.constant(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = tf.add(tf.matmul(X, W1), b1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(layer_1, W2), b2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "predict = tf.add(tf.matmul(layer_2, W3), b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "Step: 0001 cost= 0.003465736 , Training Accuracy= 0.55000\n",
      "Step: 0101 cost= 0.233506184 , Training Accuracy= 0.89000\n",
      "epoch  1\n",
      "Step: 0001 cost= 0.001582294 , Training Accuracy= 0.85000\n",
      "Step: 0101 cost= 0.162070979 , Training Accuracy= 0.89000\n",
      "epoch  2\n",
      "Step: 0001 cost= 0.001471018 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.156766032 , Training Accuracy= 0.89000\n",
      "epoch  3\n",
      "Step: 0001 cost= 0.001419145 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.153867975 , Training Accuracy= 0.89000\n",
      "epoch  4\n",
      "Step: 0001 cost= 0.001427625 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.151783273 , Training Accuracy= 0.90000\n",
      "epoch  5\n",
      "Step: 0001 cost= 0.001402225 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.149577450 , Training Accuracy= 0.90000\n",
      "epoch  6\n",
      "Step: 0001 cost= 0.001372442 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.147355777 , Training Accuracy= 0.88000\n",
      "epoch  7\n",
      "Step: 0001 cost= 0.001343118 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.144998531 , Training Accuracy= 0.88000\n",
      "epoch  8\n",
      "Step: 0001 cost= 0.001339793 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.143723105 , Training Accuracy= 0.88000\n",
      "epoch  9\n",
      "Step: 0001 cost= 0.001341926 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.141746760 , Training Accuracy= 0.90000\n",
      "epoch  10\n",
      "Step: 0001 cost= 0.001357422 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.139921227 , Training Accuracy= 0.93000\n",
      "epoch  11\n",
      "Step: 0001 cost= 0.001361429 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.138186725 , Training Accuracy= 0.91000\n",
      "epoch  12\n",
      "Step: 0001 cost= 0.001335739 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.137326236 , Training Accuracy= 0.91000\n",
      "epoch  13\n",
      "Step: 0001 cost= 0.001300726 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.135763241 , Training Accuracy= 0.89000\n",
      "epoch  14\n",
      "Step: 0001 cost= 0.001287677 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.133918784 , Training Accuracy= 0.92000\n",
      "epoch  15\n",
      "Step: 0001 cost= 0.001296100 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.131519538 , Training Accuracy= 0.92000\n",
      "epoch  16\n",
      "Step: 0001 cost= 0.001254239 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.129986556 , Training Accuracy= 0.92000\n",
      "epoch  17\n",
      "Step: 0001 cost= 0.001261996 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.130533634 , Training Accuracy= 0.89000\n",
      "epoch  18\n",
      "Step: 0001 cost= 0.001245647 , Training Accuracy= 0.87000\n",
      "Step: 0101 cost= 0.128285554 , Training Accuracy= 0.92000\n",
      "epoch  19\n",
      "Step: 0001 cost= 0.001210529 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.128027341 , Training Accuracy= 0.91000\n",
      "epoch  20\n",
      "Step: 0001 cost= 0.001249670 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.126866361 , Training Accuracy= 0.90000\n",
      "epoch  21\n",
      "Step: 0001 cost= 0.001214039 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.125254462 , Training Accuracy= 0.91000\n",
      "epoch  22\n",
      "Step: 0001 cost= 0.001144627 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.124624769 , Training Accuracy= 0.91000\n",
      "epoch  23\n",
      "Step: 0001 cost= 0.001107280 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.122582035 , Training Accuracy= 0.90000\n",
      "epoch  24\n",
      "Step: 0001 cost= 0.001124350 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.121595131 , Training Accuracy= 0.91000\n",
      "epoch  25\n",
      "Step: 0001 cost= 0.001143068 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.120089533 , Training Accuracy= 0.89000\n",
      "epoch  26\n",
      "Step: 0001 cost= 0.001108534 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.121540842 , Training Accuracy= 0.94000\n",
      "epoch  27\n",
      "Step: 0001 cost= 0.001167251 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.120591410 , Training Accuracy= 0.93000\n",
      "epoch  28\n",
      "Step: 0001 cost= 0.001081344 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.119916090 , Training Accuracy= 0.91000\n",
      "epoch  29\n",
      "Step: 0001 cost= 0.001103613 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.119617369 , Training Accuracy= 0.91000\n",
      "epoch  30\n",
      "Step: 0001 cost= 0.001197449 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.120369370 , Training Accuracy= 0.91000\n",
      "epoch  31\n",
      "Step: 0001 cost= 0.001125912 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.117638240 , Training Accuracy= 0.93000\n",
      "epoch  32\n",
      "Step: 0001 cost= 0.001176281 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.117746576 , Training Accuracy= 0.92000\n",
      "epoch  33\n",
      "Step: 0001 cost= 0.001154805 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.114774264 , Training Accuracy= 0.93000\n",
      "epoch  34\n",
      "Step: 0001 cost= 0.001206689 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.113696275 , Training Accuracy= 0.93000\n",
      "epoch  35\n",
      "Step: 0001 cost= 0.001109385 , Training Accuracy= 0.88000\n",
      "Step: 0101 cost= 0.112354482 , Training Accuracy= 0.92000\n",
      "epoch  36\n",
      "Step: 0001 cost= 0.001054831 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.109306152 , Training Accuracy= 0.94000\n",
      "epoch  37\n",
      "Step: 0001 cost= 0.001091460 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.107081266 , Training Accuracy= 0.96000\n",
      "epoch  38\n",
      "Step: 0001 cost= 0.001118245 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.109953856 , Training Accuracy= 0.92000\n",
      "epoch  39\n",
      "Step: 0001 cost= 0.001061556 , Training Accuracy= 0.89000\n",
      "Step: 0101 cost= 0.106436224 , Training Accuracy= 0.93000\n",
      "epoch  40\n",
      "Step: 0001 cost= 0.001017279 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.104919163 , Training Accuracy= 0.92000\n",
      "epoch  41\n",
      "Step: 0001 cost= 0.001084625 , Training Accuracy= 0.90000\n",
      "Step: 0101 cost= 0.104172236 , Training Accuracy= 0.92000\n",
      "epoch  42\n",
      "Step: 0001 cost= 0.001068521 , Training Accuracy= 0.91000\n",
      "Step: 0101 cost= 0.103668835 , Training Accuracy= 0.92000\n",
      "epoch  43\n",
      "Step: 0001 cost= 0.000970642 , Training Accuracy= 0.92000\n",
      "Step: 0101 cost= 0.100837039 , Training Accuracy= 0.89000\n",
      "epoch  44\n",
      "Step: 0001 cost= 0.000978617 , Training Accuracy= 0.93000\n",
      "Step: 0101 cost= 0.101555241 , Training Accuracy= 0.90000\n",
      "epoch  45\n",
      "Step: 0001 cost= 0.001022501 , Training Accuracy= 0.91000\n",
      "Step: 0101 cost= 0.099904909 , Training Accuracy= 0.89000\n",
      "epoch  46\n",
      "Step: 0001 cost= 0.001058727 , Training Accuracy= 0.91000\n",
      "Step: 0101 cost= 0.097493684 , Training Accuracy= 0.92000\n",
      "epoch  47\n",
      "Step: 0001 cost= 0.000994355 , Training Accuracy= 0.93000\n",
      "Step: 0101 cost= 0.096553379 , Training Accuracy= 0.90000\n",
      "epoch  48\n",
      "Step: 0001 cost= 0.001004704 , Training Accuracy= 0.91000\n",
      "Step: 0101 cost= 0.096635689 , Training Accuracy= 0.93000\n",
      "epoch  49\n",
      "Step: 0001 cost= 0.000996758 , Training Accuracy= 0.93000\n",
      "Step: 0101 cost= 0.098995065 , Training Accuracy= 0.93000\n",
      "Dev Accuracy= 0.86360\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        print(\"epoch \", epoch)\n",
    "        avg_cost = .0\n",
    "        for step in range(total_batch):\n",
    "            train_input = trainDataVecs[step*batch_size:step*batch_size+batch_size]\n",
    "            train_label = train_labels[step*batch_size:step*batch_size+batch_size]\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: train_input, Y: train_label})\n",
    "            avg_cost += c / total_batch\n",
    "            if step % 100 == 0:\n",
    "                acc = accuracy.eval({X: train_input, Y: train_label})\n",
    "                print(\"Step:\", '%04d' % (step+1), \"cost=\", \\\n",
    "                    \"{:.9f}\".format(avg_cost), \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    \n",
    "    acc = accuracy.eval({X: devDataVecs, Y: dev_labels})\n",
    "    print(\"Dev Accuracy= \" + \"{:.5f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
